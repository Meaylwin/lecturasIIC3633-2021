<h1>Lectura 6: Deep learning based recommender system: A survey and new perspectives. pág. 1-38 </h1>
<h3>Zhang, S., Yao, L., Sun, A., & Tay, Y. </h3>  

En esta primera mitad del texto se introduce el concepto de Deep Learning aplicado en el ámbito de los sistemas recomendadores. Los autores hicieron una recopilación de varios *papers* sobre este tópico y hacen un resumen de las técnicas ya implementadas que más les llamaron la atención. Primero, se hace una breve introducción sobre los aspectos que diferencian esta compilación de *papers* de *deep learning* en sistemas recomendadores con los que ya se han publicado, señalando en especial que este contiene un resumen más profundo de los detalles de los esfuerzos y problemas que tiene esta área. Luego, se hace una explicación general sobre las técnicas utilizadas en los sistemas recomendadores y en *deep learning*. Después, se comienza a hablar sobre el estado del arte de los sistemas recomendadores basados en *deep learning*. Estos se pueden separar en dos grandes categorías, en recomendaciones con *Neural Building Blocks* y en recomendaciones con modelos híbridos profundos. Dentro de la primera categoría, los modelos que se describen en esta primera parte son: **Multilayer Perceptron (MLP)**, **Autoencoder (AE)**, **Convolutional Neural Network (CNN)**.

Los autores detallan en el artículo las ventajas y desventajas de los modelos de recomendación basados en aprendizaje profundo. Así, para cada tipo de algoritmo, el artículo explica de manera breve cómo funciona, pero la explicación de ventajas y desventajas son un poco ambiguas a mi parecer. Un ejemplo: ‘Aprendizaje de representación de funciones con Autoencoder’, los autores mencionan cómo funcionan las representaciones para recomendación. Sin embargo, no hay mayores detalles de ventajas y desventajas, que podría ser algo muy interesante conocerlo. En ese sentido, y por el objetivo del artículo quizá fue suficiente brindando un survey de las investigaciones, o quizá al continuar la lectura del artículo presentará mayor enfoque en ello. 

Es muy claro que la popularidad del Deep Learning ha aumentado rápidamente en esta última década debido a su gran contribución en el area de la computación y de la ciencia en general. Cada día las personas estamos expuestos a una cantidad de información mayor en comparación a cualquier otro periodo de la historia humana [1]. Y esto se puede percibir aún más en este periodo *online*; cada vez que utilizamos Internet absorbemos una gran cantidad de de información, con la cual podemos entender mucho acerca de los usuarios, los servicios y los productos. Es preciso destacar que esto permite encontrar información muy específica, lo cual solo se puede lograr con un flujo enorme de datos y buenos algoritmos que permitan acceder a ella de forma rápida. Esto permite encontrar información que, en muchos casos, el usaurio no sabía como encontrar y los sistemas recomendadres le ayudan en este labor. Y esto solo es posible con las correlaciones que se generan en las extensas redes de datos. Es por esto que, en mi opinión, esta tecnología no podría haber llegado más temprano. Estamos viviendo una época en que la información es utilizado prácticamente como moneda de cambio y genera enormes cantidades de transacciones todos los días. Es por esto que hoy en día se puede superar fácilmente la barrera más grande que tiene el Deep Learning, que es su "arranque en frío" deficiente, es decir, su baja capacidad para funcionar con poca información. Por esto es mala idea implementar esta técnica en ámbitos con poco acceso a información, como podría ser el caso de una "start-up".


[1]R. Alleyne. (2011) Welcome to the information Age - 174 papers a day. Recuperado de: https://www.telegraph.co.uk/news/science/science-news/8316534/Welcome-to-the-information-age-174-newspapers-a-day.html 